{
    "optimizer_name": {"_type": "choice", "_value": ["SGD", "Adagrad", "RMSprop", "Adam", "Adamax", "Adadelta"]},
    "learning_rate": {"_type": "choice", "_value": [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]},
    "weight_decay": {"_type": "choice", "_value": [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]},
    "momentum": {"_type": "uniform", "_value": [0.7, 0.99]},

    "lr_scheduler_name": {"_type": "choice", "_value": ["ExponentialLR", "StepLR", "MultiStepLR", "CosineAnnealingLR", "CosineAnnealingWarmRestarts", "OneCycleLR", "ReduceLROnPlateau"]},
    "gamma": {"_type": "uniform", "_value": [0.8, 0.999]},
    "step_size": {"_type": "choice", "_value": [2, 5]},
    "T_max": {"_type": "choice", "_value": [2, 5]},
    "T_0": {"_type": "choice", "_value": [2, 5]},
    "T_mult": {"_type": "choice", "_value": [2, 3, 4]},
    "patience": {"_type": "choice", "_value": [2, 3, 4]},
    "factor": {"_type": "uniform", "_value": [0.1, 0.9]},

    "update_weight_freq": {"_type": "choice", "_value": [16, 32, 64, 128, 256]}
}


